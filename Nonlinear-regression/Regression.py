# -*- coding: utf-8 -*-
"""NLP.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cjRUBkWfOywr6j0LTOaL-v-xrqpBvYdl
"""

import time
import pandas as pd
import numpy as np
from sklearn.svm import LinearSVC
from sklearn.metrics import accuracy_score

from sklearn.feature_extraction.text import CountVectorizer

from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import MultinomialNB

URL_Train= "https://raw.githubusercontent.com/cacoderquan/Sentiment-Analysis-on-the-Rotten-Tomatoes-movie-review-dataset/master/train.tsv"
URL_Test="https://raw.githubusercontent.com/cacoderquan/Sentiment-Analysis-on-the-Rotten-Tomatoes-movie-review-dataset/master/test.tsv"

train=pd.read_csv(URL_Train,sep='\t')
test= pd.read_csv(URL_Test, sep='\t')

fullSent = train.loc[train.groupby('SentenceId')['PhraseId'].idxmin()]
fullSent.head()

BoW_vectorizer = CountVectorizer(strip_accents='unicode',
                                 ngram_range=(1,3),
                                 analyzer='word',
                                 min_df=5,
                                 max_df=0.5)

BoW_vectorizer.fit(list(fullSent['Phrase']))

fullSent.head()

phrase = fullSent['Phrase']
sentiment = fullSent['Sentiment']

phrase.shape, sentiment.shape

X_train, X_test, Y_train, Y_test = train_test_split(phrase,
                                                    sentiment,
                                                    test_size=0.2,
                                                    random_state=4)



X_train.shape, Y_train.shape, X_test.shape, Y_test.shape

from keras.utils import to_categorical
y_train = to_categorical(Y_train)
y_train.shape

y_test = to_categorical(Y_test)
y_test.shape

train_bow= BoW_vectorizer.transform(X_train)
  train_bow= np.array(train_bow.toarray())
  train_bow = train_bow.reshape(train_bow.shape[0],train_bow.shape[1],1)
  train_bow.shape

test_bow= BoW_vectorizer.transform(X_test)
test_bow_reshape= np.array(test_bow.toarray())
test_bow_reshape= test_bow_reshape.reshape(test_bow_reshape.shape[0],test_bow_reshape.shape[1],1)
test_bow_reshape.shape

bow_feature_vec = pd.DataFrame(test_bow.toarray(), columns= BoW_vectorizer.get_feature_names())
bow_feature_vec.head(25)

from keras import backend as K
def recall_m(y_true,y_pred):
  true_positives = K.sum(K.round(K.clip(y_true*y_pred,0,1)))
  possible_positives = K.sum(K.round(K.clip(y_true, 0,1)))
  recall = true_positives / (possible_positives + K.epsilon())
  return recall

def precision_m(y_true, y_pred):
  true_positives = K.sum(K.round(K.clip(y_true*y_pred, 0,1)))
  predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))
  precision = true_positives / (predicted_positives + K.epsilon())
  return precision

def f1_m(y_true, y_pred):
  precision= precision_m(y_true, y_pred)
  recall= recall_m(y_true, y_pred)
  return 2*((precision*recall)/(precision+recall+K.epsilon()))

from keras.models import Sequential
from keras.layers import Conv1D, MaxPooling1D, Dense, Dropout, Flatten
from keras.layers import Activation, Conv1D, GlobalMaxPooling1D
from keras import optimizers
from keras import layers

def cnn_model(fea_matrix, n_class, mode,compiler):
  model= Sequential()
  model.add(Conv1D(filters=64, kernel_size=2, activation= 'relu', input_shape= (fea_matrix.shape[1],fea_matrix.shape[2])))
  model.add(MaxPooling1D(pool_size=2))
  model.add(Conv1D(filters=64, kernel_size=2, activation= 'relu'))
  model.add(MaxPooling1D(pool_size=2))
  model.add(Conv1D(filters=64, kernel_size=2, activation= 'relu'))
  model.add(MaxPooling1D(pool_size=2))
  model.add(Flatten())
  model.add(Activation('relu'))
  model.add(Dense(n_class))
  if n_class == 1 and mode =="cla":
    model.add(Activation('sigmoid'))
    model.compile(optimizer= compiler, loss='binary_crossentropy', metrics=['acc', f1_m, precision_m, recall_m])
  else:
    model.add(Activation('softmax'))
    model.compile(optimizer= compiler, loss='categorical_crossentropy', metrics=['acc', f1_m, precision_m, recall_m])
    
  return model

lr=1e-3
batch_size= 64
num_epochs= 100
decay=1e-4
mode= "reg"
n_class = 5
adm = optimizers.Adam(lr=lr, decay=decay)
sgd= optimizers.SGD(lr=lr, nesterov= True, momentum=0.7, decay=decay)
Nadam= optimizers.Nadam(lr=lr, beta_1=0.9, beta_2=0.999, epsilon= 1e-08)
model=cnn_model(train_bow, n_class, mode, Nadam)

Y_train = to_categorical(y_train)
model.fit(train_bow, y_train, batch_size=batch_size, epochs=num_epochs, verbose=1, validation_split=0.2)

def get_metrics (accuracy,f1_score,precision,recall):
  print('CNN model performance')
  print('Accuracy:', np.round(accuracy,4))
  print('Precision: ', np.round(precision,4))
  print("recall:", np.round(recall,4 ))
  print("f1score:", np.round(f1_score,4 ))
loss, accuracy, f1_score, precision, recall = model.evaluate(test_bow_reshape, y_test, verbose=False)

get_metrics(accuracy,f1_score, precision, recall)